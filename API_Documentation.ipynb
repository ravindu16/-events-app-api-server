{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwKv0eEQqy8WtHb/A6HTqW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravindu16/-events-app-api-server/blob/main/API_Documentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6w2daKaCH6hh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "158269cf-101d-4aed-8a83-0795d081b4ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.72)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.42)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.12)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.4-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.2/153.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.9-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: filetype, python-dotenv, ormsgpack, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, langgraph-sdk, dataclasses-json, langgraph-checkpoint, google-ai-generativelanguage, langgraph-prebuilt, langchain-google-genai, langgraph, langchain-community\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 filetype-1.2.0 google-ai-generativelanguage-0.6.18 httpx-sse-0.4.1 langchain-community-0.3.27 langchain-google-genai-2.1.9 langgraph-0.6.4 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.0 marshmallow-3.26.1 mypy-extensions-1.1.0 ormsgpack-1.10.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "ac56d51c5f214d15ba34abf77094590c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install langgraph langchain-google-genai langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install grandalf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaeTKFhGIUhF",
        "outputId": "e0049a15-85cc-4dcc-e7d5-837281834556"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting grandalf\n",
            "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from grandalf) (3.2.3)\n",
            "Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: grandalf\n",
            "Successfully installed grandalf-0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn8ozWFltRFF",
        "outputId": "314d02c6-8bec-4287-d799-6571cb243d6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.1)\n",
            "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install plantuml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phK5KkdVtVM1",
        "outputId": "36f9c099-0bff-4a89-95b6-0cc3fbb9d29f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plantuml\n",
            "  Downloading plantuml-0.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.11/dist-packages (from plantuml) (0.22.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2->plantuml) (3.2.3)\n",
            "Downloading plantuml-0.3.0-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: plantuml\n",
            "Successfully installed plantuml-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary packages for building graph and state machine\n",
        "from typing import Annotated, Literal\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.schema import HumanMessage, SystemMessage"
      ],
      "metadata": {
        "id": "3nJiWEc3IZFz"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create Stategraph\n",
        "class State(TypedDict):\n",
        "  messages: Annotated[list[str], add_messages]\n",
        "  user_input: str\n",
        "  message_type: str"
      ],
      "metadata": {
        "id": "wGuAsG-XIgis"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create llm\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", api_key=\"AIzaSyCOJzozWkPtZh4BBSHEn05ZnLHt0s6Huh8\")"
      ],
      "metadata": {
        "id": "4rO04XDoIjeb"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MessageClassifier(BaseModel):\n",
        "  message_type: Literal[\"Class_Diagram\", \"Sequence_Diagram\", \"Business_Outcome\"]=Field(description=\"classify the message\")"
      ],
      "metadata": {
        "id": "yru-HiSmInOP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "def router_message(state: State):\n",
        "  user_input = state[\"messages\"][-1].content\n",
        "  classifier_llm = llm.with_structured_output(MessageClassifier)\n",
        "  system_prompt = '''\n",
        "                  classify user input to Class_Diagram, Sequence_Diagram or Business_Outcome based on below criteria\n",
        "                  'Class_Diagram': if user input is related to Class diagram, try to understand the code in repository \"https://github.com/mikeknep/SOLID\" and create a class diagram\n",
        "                  'Sequence_Diagram': if user input is related to sequence diagram, try to understand the code in repository \"https://github.com/mikeknep/SOLID\" and create a sequence diagram\n",
        "                  'Business_Outcome': if user input want to know the business Usecase , try to understand the code in repository \"https://github.com/mikeknep/SOLID\" and share the output\n",
        "                  'create_documentation': if user input want a documentation , create a documentation\n",
        "                  '''\n",
        "  result = classifier_llm.invoke(\n",
        "      [\n",
        "        {  \"role\": \"system\",\n",
        "           \"content\": system_prompt\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": user_input\n",
        "        }\n",
        "\n",
        "      ]\n",
        "  )\n",
        "  return {\"messages\":[{\"role\":\"assistant\",\"content\":result.message_type}],\"user_input\":state[\"messages\"][-1].content,\"message_type\":result.message_type}\n",
        "\n"
      ],
      "metadata": {
        "id": "X7hCp6fZI0fJ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import re\n",
        "from plantuml import PlantUML, PlantUMLHTTPError\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "import os\n",
        "\n",
        "def Business_Outcome(state):\n",
        "  user_input = state[\"user_input\"]\n",
        "  system_prompt = 'try to understand the code in repository \"https://github.com/udaychandra/user-crud-microservice/tree/master\" and share the Business outcome in 2 sentences'\n",
        "  result = llm.invoke(\n",
        "      [\n",
        "        {  \"role\": \"system\",\n",
        "           \"content\": system_prompt\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": user_input\n",
        "        }\n",
        "\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  document = Document()\n",
        "\n",
        "  business_usecase_text = result.content # Extract the string content\n",
        "  print(business_usecase_text)\n",
        "  document.add_heading(\"Business Usecase Document\", level=0)\n",
        "  document.add_paragraph(business_usecase_text)\n",
        "\n",
        "  # Initialize PlantUML client, using the public server\n",
        "  plantuml = PlantUML(url='http://www.plantuml.com/plantuml/img/')\n",
        "\n",
        "  # --- Sequence Diagram Generation ---\n",
        "  system_prompt_seq = 'try to understand the code in repository \"https://github.com/udaychandra/user-crud-microservice/tree/master\" and create a sequence diagram for the same using plantuml syntax. Only provide the plantuml code block, nothing else.'\n",
        "  result_seq = llm.invoke(\n",
        "      [\n",
        "        {  \"role\": \"system\",\n",
        "           \"content\": system_prompt_seq\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": user_input\n",
        "        }\n",
        "\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  diagram_content_with_markdown_seq = result_seq.content # Extract the string content\n",
        "\n",
        "  # Extract the PlantUML code block using a regular expression\n",
        "  match_seq = re.search(r\"```plantuml\\n(.*?)\\n```\", diagram_content_with_markdown_seq, re.DOTALL)\n",
        "  if match_seq:\n",
        "      diagram_content_seq = match_seq.group(1)\n",
        "  else:\n",
        "      # If no plantuml block is found, assume the whole content is the diagram code\n",
        "      diagram_content_seq = diagram_content_with_markdown_seq\n",
        "\n",
        "\n",
        "  # Write the diagram content to a temporary file\n",
        "  temp_file_path_seq = None\n",
        "  try:\n",
        "      with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.plantuml') as temp_file:\n",
        "          temp_file.write(diagram_content_seq)\n",
        "          temp_file_path_seq = temp_file.name\n",
        "\n",
        "      file_path_seq ='/content/sequence_diagram.png'\n",
        "      plantuml.processes_file(temp_file_path_seq, outfile=file_path_seq)\n",
        "      document.add_heading(\"Sequence Diagram\", level=0)\n",
        "      document.add_picture(file_path_seq, width=Inches(6.0), height=Inches(4.0))\n",
        "  except PlantUMLHTTPError as e:\n",
        "      print(f\"PlantUML HTTP Error for Sequence Diagram: Status - {e.response.status}, Reason - {e.response.reason}, Content - {e.content}\")\n",
        "      error_message = f\"Failed to generate Sequence Diagram due to a PlantUML HTTP error (Status: {e.response.status}, Reason: {e.response.reason}).\"\n",
        "      if e.content and b\"Syntax Error?\" in e.content:\n",
        "          error_message += \" Likely a syntax error in the generated PlantUML code.\"\n",
        "          error_message += f\"\\nProblematic PlantUML code:\\n{diagram_content_seq}\"\n",
        "      document.add_paragraph(error_message)\n",
        "  finally:\n",
        "      # Clean up the temporary file\n",
        "      if temp_file_path_seq and os.path.exists(temp_file_path_seq):\n",
        "          os.unlink(temp_file_path_seq)\n",
        "\n",
        "\n",
        "  # --- Class Diagram Generation ---\n",
        "  # Refined prompt for class diagram\n",
        "  system_prompt_class = \"\"\"try to understand the code in repository \"https://github.com/udaychandra/user-crud-microservice/tree/master\" and create a class diagram for the same using correct PlantUML syntax.\n",
        "  Only provide the PlantUML code block, starting with @startuml and ending with @enduml.\n",
        "  Ensure correct syntax for classes, attributes, methods, and relationships (inheritance, composition, aggregation, association, etc.).\n",
        "  Example syntax:\n",
        "  class ClassName {\n",
        "    - attribute: Type\n",
        "    + method(parameter: Type): ReturnType\n",
        "  }\n",
        "  ClassA --|> ClassB : inheritance\n",
        "  ClassC *-- ClassD : composition\n",
        "  ClassE o-- ClassF : aggregation\n",
        "  ClassG --> ClassH : association\n",
        "  \"\"\"\n",
        "  result_class = llm.invoke(\n",
        "      [\n",
        "        {  \"role\": \"system\",\n",
        "           \"content\": system_prompt_class\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": user_input\n",
        "        }\n",
        "\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  diagram_content_with_markdown_class = result_class.content # Extract the string content\n",
        "\n",
        "  # Extract the PlantUML code block using a regular expression\n",
        "  match_class = re.search(r\"```plantuml\\n(.*?)\\n```\", diagram_content_with_markdown_class, re.DOTALL)\n",
        "  if match_class:\n",
        "      diagram_content_class = match_class.group(1)\n",
        "  else:\n",
        "      # If no plantuml block is found, assume the whole content is the diagram code\n",
        "      diagram_content_class = diagram_content_with_markdown_class\n",
        "\n",
        "  temp_file_path_class = None\n",
        "  # Write the diagram content to a temporary file\n",
        "  try:\n",
        "      with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.plantuml') as temp_file:\n",
        "          temp_file.write(diagram_content_class)\n",
        "          temp_file_path_class = temp_file.name\n",
        "\n",
        "      file_path_class ='/content/class_diagram.png'\n",
        "      plantuml.processes_file(temp_file_path_class, outfile=file_path_class)\n",
        "      document.add_heading(\"Class Diagram\", level=0)\n",
        "      document.add_picture(file_path_class, width=Inches(6.0), height=Inches(3.0))\n",
        "  except PlantUMLHTTPError as e:\n",
        "      print(f\"PlantUML HTTP Error for Class Diagram: Status - {e.response.status}, Reason - {e.response.reason}, Content - {e.content}\")\n",
        "      error_message = f\"Failed to generate Class Diagram due to a PlantUML HTTP error (Status: {e.response.status}, Reason: {e.response.reason}).\"\n",
        "      if e.content and b\"Syntax Error?\" in e.content:\n",
        "          error_message += \" Likely a syntax error in the generated PlantUML code.\"\n",
        "          error_message += f\"\\nProblematic PlantUML code:\\n{diagram_content_class}\"\n",
        "      document.add_paragraph(error_message)\n",
        "  finally:\n",
        "       # Clean up the temporary file\n",
        "      if temp_file_path_class and os.path.exists(temp_file_path_class):\n",
        "          os.unlink(temp_file_path_class)\n",
        "\n",
        "\n",
        "  # --- Endpoint Details ---\n",
        "  system_prompt_endpoints = 'try to understand the code in repository \"https://github.com/udaychandra/user-crud-microservice/tree/master\" and provide the endpoint details , HTTP Methods used and its request and response structure in json format'\n",
        "  endpoints_details = llm.invoke(\n",
        "      [\n",
        "        {  \"role\": \"system\",\n",
        "           \"content\": system_prompt_endpoints\n",
        "        },\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": user_input\n",
        "        }\n",
        "\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  print(endpoints_details.content)\n",
        "  endpoints_details_text = endpoints_details.content # Extract the string content\n",
        "  document.add_heading(\"Endpoint Details \", level=0)\n",
        "  document.add_paragraph(endpoints_details_text)\n",
        "\n",
        "\n",
        "  # --- Save Document ---\n",
        "  final_document_path='/content/business_outcome_document.docx'\n",
        "  document.save(final_document_path)\n",
        "\n",
        "\n",
        "  return {\"messages\": state[\"messages\"] + [{\"role\":\"assistant\",\"content\":f\"Documentation created at: {final_document_path}\"}], \"business_outcome_document_path\": final_document_path}"
      ],
      "metadata": {
        "id": "Wr7CdQ7fUD9d"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_bulider = StateGraph(State)\n",
        "graph_bulider.add_node(\"classifer\",router_message)\n",
        "graph_bulider.add_edge(START,\"classifer\")\n",
        "graph_bulider.add_node(\"Business_Outcome\",Business_Outcome)\n",
        "#graph_bulider.add_node(\"Sequence_Diagram\",Sequence_Diagram)\n",
        "#graph_bulider.add_node(\"Class_Diagram\",Class_Diagram)\n",
        "#graph_bulider.add_node(\"create_documentation\",create_documentation)\n",
        "graph_bulider.add_conditional_edges(\"classifer\", lambda state:state.get(\"message_type\"),{\"Business_Outcome\":\"Business_Outcome\"})\n",
        "\n",
        "graph_bulider.add_edge(\"Business_Outcome\",END)\n",
        "#graph_bulider.add_edge(\"Sequence_Diagram\",\"Class_Diagram\")\n",
        "#graph_bulider.add_edge(\"Class_Diagram\",\"create_documentation\")\n",
        "#graph_bulider.add_edge(\"create_documentation\",END)\n",
        "graph = graph_bulider.compile()"
      ],
      "metadata": {
        "id": "ufaFo4TITnCa"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(graph.get_graph().draw_ascii())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb1tmJitULVh",
        "outputId": "097ffd38-e344-42a8-a5e1-5cf312d9a07b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    +-----------+    \n",
            "    | __start__ |    \n",
            "    +-----------+    \n",
            "          *          \n",
            "          *          \n",
            "          *          \n",
            "    +-----------+    \n",
            "    | classifer |    \n",
            "    +-----------+    \n",
            "          .          \n",
            "          .          \n",
            "          .          \n",
            "+------------------+ \n",
            "| Business_Outcome | \n",
            "+------------------+ \n",
            "          *          \n",
            "          *          \n",
            "          *          \n",
            "    +---------+      \n",
            "    | __end__ |      \n",
            "    +---------+      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.invoke({\"messages\":[{\"role\":\"user\", \"content\":\"business Usecase\"}]})\n",
        "#print(result)\n",
        "#result[\"messages\"][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aayLleyZLot",
        "outputId": "93ae904f-d4a2-46d1-dee1-13ae3a817baf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The user-crud-microservice repository provides a basic, scalable foundation for managing user data in a microservices architecture. It enables businesses to efficiently create, read, update, and delete user information, which is essential for user management, authentication, and personalization across various applications and services.\n",
            "Okay, I've analyzed the code in the repository \"https://github.com/udaychandra/user-crud-microservice/tree/master\".  Based on the code structure and file names, it appears to be a basic CRUD (Create, Read, Update, Delete) microservice for managing user data.\n",
            "\n",
            "Here's a breakdown of the endpoints, HTTP methods, and the expected request/response structures in JSON format, along with the assumed business use case:\n",
            "\n",
            "**Business Use Case:**\n",
            "\n",
            "The microservice aims to provide a simple and independent way to manage user information.  This could be used as a building block for a larger application where user management is a key requirement.  For example:\n",
            "\n",
            "*   A social media platform might use this service to store basic user profiles.\n",
            "*   An e-commerce website could use it to keep track of customer accounts.\n",
            "*   An internal company application might use it to manage employee information.\n",
            "\n",
            "**Endpoint Details:**\n",
            "\n",
            "Based on the `routes/users.js` file and the general structure of a CRUD application, I infer the following endpoints:\n",
            "\n",
            "1.  **`/users`** (Base Endpoint for User Management)\n",
            "\n",
            "    *   **HTTP Method: `GET`**\n",
            "        *   **Description:** Retrieves a list of all users.\n",
            "        *   **Request:**  None (usually, but could potentially support query parameters for filtering/pagination)\n",
            "        *   **Response (JSON):**\n",
            "\n",
            "            ```json\n",
            "            [\n",
            "              {\n",
            "                \"id\": \"string (UUID)\",\n",
            "                \"firstName\": \"string\",\n",
            "                \"lastName\": \"string\",\n",
            "                \"email\": \"string\",\n",
            "                \"phone\": \"string\"\n",
            "              },\n",
            "              {\n",
            "                \"id\": \"string (UUID)\",\n",
            "                \"firstName\": \"string\",\n",
            "                \"lastName\": \"string\",\n",
            "                \"email\": \"string\",\n",
            "                \"phone\": \"string\"\n",
            "              },\n",
            "              // ... more users\n",
            "            ]\n",
            "            ```\n",
            "\n",
            "    *   **HTTP Method: `POST`**\n",
            "        *   **Description:** Creates a new user.\n",
            "        *   **Request (JSON):**\n",
            "\n",
            "            ```json\n",
            "            {\n",
            "              \"firstName\": \"string\",\n",
            "              \"lastName\": \"string\",\n",
            "              \"email\": \"string\",\n",
            "              \"phone\": \"string\"\n",
            "            }\n",
            "            ```\n",
            "\n",
            "        *   **Response (JSON - Success):**  (Likely returns the newly created user, including the generated `id`)\n",
            "\n",
            "            ```json\n",
            "            {\n",
            "              \"id\": \"string (UUID)\",\n",
            "              \"firstName\": \"string\",\n",
            "              \"lastName\": \"string\",\n",
            "              \"email\": \"string\",\n",
            "              \"phone\": \"string\"\n",
            "            }\n",
            "            ```\n",
            "\n",
            "        *   **Response (JSON - Error):**\n",
            "\n",
            "            ```json\n",
            "            {\n",
            "              \"error\": \"string (Description of the error, e.g., 'Email already exists')\"\n",
            "            }\n",
            "            ```\n",
            "\n",
            "2.  **`/users/:id`** (Endpoint for a Specific User)\n",
            "\n",
            "    *   **HTTP Method: `GET`**\n",
            "        *   **Description:** Retrieves a specific user by ID.\n",
            "        *   **Request:**  None (ID is in the URL)\n",
            "        *   **Response (JSON - Success):**\n",
            "\n",
            "            ```json\n",
            "            {\n",
            "              \"id\": \"string (UUID)\",\n",
            "              \"firstName\": \"string\",\n",
            "              \"lastName\": \"string\",\n",
            "              \"email\": \"string\",\n",
            "              \"phone\": \"string\"\n",
            "            }\n",
            "            ```\n",
            "\n",
            "        *   **Response (JSON - Error):**\n",
            "\n",
            "            ```json\n",
            "            {\n",
            "              \"error\": \"string (e.g., 'User not found')\"\n",
            "            }\n",
            "            ```\n",
            "\n",
            "    *   **HTTP Method: `PUT`**\n",
            "        *   **Description:** Updates an existing user.\n",
            "        *   **Request (JSON):**  (Typically includes all the fields to update, although a `PATCH` request might be more appropriate for partial updates)\n",
            "\n",
            "            ```json\n",
            "            {\n",
            "              \"firstName\": \"string\",\n",
            "              \"lastName\": \"string\",\n",
            "              \"email\": \"string\",\n",
            "              \"phone\": \"string\"\n",
            "            }\n",
            "            ```\n",
            "\n",
            "        *   **Response (JSON - Success):** (Likely returns the updated user)\n",
            "\n",
            "            ```json\n",
            "            {\n",
            "              \"id\": \"string (UUID)\",\n",
            "              \"firstName\": \"string\",\n",
            "              \"lastName\": \"string\",\n",
            "              \"email\": \"string\",\n",
            "              \"phone\": \"string\"\n",
            "            }\n",
            "            ```\n",
            "\n",
            "        *   **Response (JSON - Error):**\n",
            "\n",
            "            ```json\n",
            "            {\n",
            "              \"error\": \"string (e.g., 'User not found', 'Invalid data')\"\n",
            "            }\n",
            "            ```\n",
            "\n",
            "    *   **HTTP Method: `DELETE`**\n",
            "        *   **Description:** Deletes a user.\n",
            "        *   **Request:** None (ID is in the URL)\n",
            "        *   **Response (JSON - Success):** (Often returns a 204 No Content, or a simple success message)\n",
            "\n",
            "            ```json\n",
            "            {\n",
            "              \"message\": \"User deleted successfully\"\n",
            "            }\n",
            "            ```\n",
            "\n",
            "        *   **Response (JSON - Error):**\n",
            "\n",
            "            ```json\n",
            "            {\n",
            "              \"error\": \"string (e.g., 'User not found')\"\n",
            "            }\n",
            "            ```\n",
            "\n",
            "**Important Considerations and Assumptions:**\n",
            "\n",
            "*   **Error Handling:**  The error responses are inferred.  The actual error structure might be different.  Proper error handling (e.g., using HTTP status codes like 400 Bad Request, 404 Not Found, 500 Internal Server Error) is crucial for a robust microservice.\n",
            "*   **Validation:**  The code likely includes validation to ensure that the data being sent is in the correct format and meets certain criteria (e.g., email format, required fields).\n",
            "*   **Database:** The code uses MongoDB for data storage, as indicated by the `config/database.js` file and the `models/User.js` file.\n",
            "*   **UUIDs:** The code uses UUIDs for the user IDs.\n",
            "*   **Authentication/Authorization:**  This simple example *doesn't* appear to include any authentication or authorization. In a real-world scenario, you would need to add security measures to protect the user data.\n",
            "*   **Missing Features:**  More advanced features like pagination, sorting, and filtering are not present in this basic example but are often needed in a production environment.\n",
            "*   **Idempotency:** PUT and DELETE requests should ideally be idempotent.  This means that making the same request multiple times has the same effect as making it once.\n",
            "\n",
            "To get a 100% accurate picture, you would need to run the code and examine the actual responses. However, this analysis provides a solid understanding of the microservice's functionality based on the repository's contents.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='business Usecase', additional_kwargs={}, response_metadata={}, id='5a655b36-f7a3-4568-af7e-a08937361566'),\n",
              "  AIMessage(content='Business_Outcome', additional_kwargs={}, response_metadata={}, id='65235fa2-1880-49d3-a02f-419647ab08b7'),\n",
              "  AIMessage(content='Documentation created at: /content/business_outcome_document.docx', additional_kwargs={}, response_metadata={}, id='91fc9b4f-51d7-4d3f-9df6-ccb88b46e86e')],\n",
              " 'user_input': 'business Usecase',\n",
              " 'message_type': 'Business_Outcome'}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}